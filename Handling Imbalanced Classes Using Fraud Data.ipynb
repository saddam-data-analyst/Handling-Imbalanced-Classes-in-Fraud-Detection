{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81eeae5-6fb3-424b-84c3-52c1b0afbaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Libraries:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "620044ff-eea7-4164-8a27-1f90c87c2cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data:\n",
    "fraud_data = pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Imbalanced_classes/master/fraud_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52724558-766c-4abd-ba04-d2fa496a60ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>ProductCD</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card4</th>\n",
       "      <th>card5</th>\n",
       "      <th>...</th>\n",
       "      <th>id_31</th>\n",
       "      <th>id_32</th>\n",
       "      <th>id_33</th>\n",
       "      <th>id_34</th>\n",
       "      <th>id_35</th>\n",
       "      <th>id_36</th>\n",
       "      <th>id_37</th>\n",
       "      <th>id_38</th>\n",
       "      <th>DeviceType</th>\n",
       "      <th>DeviceInfo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2994681</td>\n",
       "      <td>0</td>\n",
       "      <td>242834</td>\n",
       "      <td>25.000</td>\n",
       "      <td>H</td>\n",
       "      <td>9803</td>\n",
       "      <td>583.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>firefox 56.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1920x1080</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>desktop</td>\n",
       "      <td>rv:56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3557242</td>\n",
       "      <td>0</td>\n",
       "      <td>15123000</td>\n",
       "      <td>117.000</td>\n",
       "      <td>W</td>\n",
       "      <td>7919</td>\n",
       "      <td>194.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3327470</td>\n",
       "      <td>0</td>\n",
       "      <td>8378575</td>\n",
       "      <td>73.773</td>\n",
       "      <td>C</td>\n",
       "      <td>12778</td>\n",
       "      <td>500.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>mastercard</td>\n",
       "      <td>224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3118781</td>\n",
       "      <td>0</td>\n",
       "      <td>2607840</td>\n",
       "      <td>400.000</td>\n",
       "      <td>R</td>\n",
       "      <td>12316</td>\n",
       "      <td>548.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>195.0</td>\n",
       "      <td>...</td>\n",
       "      <td>mobile safari generic</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1136x640</td>\n",
       "      <td>match_status:2</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>T</td>\n",
       "      <td>F</td>\n",
       "      <td>mobile</td>\n",
       "      <td>iOS Device</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3459772</td>\n",
       "      <td>0</td>\n",
       "      <td>12226544</td>\n",
       "      <td>31.950</td>\n",
       "      <td>W</td>\n",
       "      <td>9002</td>\n",
       "      <td>453.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>visa</td>\n",
       "      <td>226.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt ProductCD  card1  \\\n",
       "0        2994681        0         242834          25.000         H   9803   \n",
       "1        3557242        0       15123000         117.000         W   7919   \n",
       "2        3327470        0        8378575          73.773         C  12778   \n",
       "3        3118781        0        2607840         400.000         R  12316   \n",
       "4        3459772        0       12226544          31.950         W   9002   \n",
       "\n",
       "   card2  card3       card4  card5  ...                  id_31  id_32  \\\n",
       "0  583.0  150.0        visa  226.0  ...           firefox 56.0   24.0   \n",
       "1  194.0  150.0  mastercard  166.0  ...                    NaN    NaN   \n",
       "2  500.0  185.0  mastercard  224.0  ...                    NaN    NaN   \n",
       "3  548.0  150.0        visa  195.0  ...  mobile safari generic   32.0   \n",
       "4  453.0  150.0        visa  226.0  ...                    NaN    NaN   \n",
       "\n",
       "       id_33           id_34  id_35 id_36 id_37  id_38  DeviceType  DeviceInfo  \n",
       "0  1920x1080  match_status:2      T     F     T      T     desktop     rv:56.0  \n",
       "1        NaN             NaN    NaN   NaN   NaN    NaN         NaN         NaN  \n",
       "2        NaN             NaN    NaN   NaN   NaN    NaN         NaN         NaN  \n",
       "3   1136x640  match_status:2      T     F     T      F      mobile  iOS Device  \n",
       "4        NaN             NaN    NaN   NaN   NaN    NaN         NaN         NaN  \n",
       "\n",
       "[5 rows x 434 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting Basic idea about the data:\n",
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c66cd78-de3e-47c1-8b24-2b1f9798679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59054 entries, 0 to 59053\n",
      "Columns: 434 entries, TransactionID to DeviceInfo\n",
      "dtypes: float64(385), int64(18), object(31)\n",
      "memory usage: 195.5+ MB\n"
     ]
    }
   ],
   "source": [
    "fraud_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "688efd60-06df-4012-baa9-60438808ba77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    57049\n",
       "1     2005\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at the target variable:\n",
    "fraud_data.isFraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e476e132-60bb-4b8d-8334-c9e63adb7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 means not fraud and 1 means is Fraud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b0aa51-ed79-4232-9108-23e919389c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    96.604802\n",
       "1     3.395198\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.isFraud.value_counts() / len(fraud_data) * 100  # Get the percentage of unique values in the variable 'isFraud'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b5ecb5a-9931-4dfd-81ca-fee97c139822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are only 3% of the data which are fraud and the rest 97% are not fraud. This is clearly a class imbalance problem. \n",
    "# In this notebook we will look to solve this type of problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ee7a642-f5fe-4048-9464-422daf2297e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID      0.000000\n",
       "isFraud            0.000000\n",
       "TransactionDT      0.000000\n",
       "TransactionAmt     0.000000\n",
       "ProductCD          0.000000\n",
       "                    ...    \n",
       "id_36             75.945745\n",
       "id_37             75.945745\n",
       "id_38             75.945745\n",
       "DeviceType        75.979612\n",
       "DeviceInfo        79.813391\n",
       "Length: 434, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing Values:\n",
    "fraud_data.isnull().sum() / len(fraud_data) * 100    # get the percentage of missing values in each columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01cf1254-baeb-4903-8528-ff3d5f425fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = fraud_data.isnull().sum() >0  # TO get the Boolean results for the column with missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0995eda-7a0d-44ae-974a-891a02a7cd58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     414\n",
       "False     20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.value_counts()   # Get the count of column with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5565c977-8b6e-449a-acec-51edfdf9fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of 434 columns, 414 have some missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01265af2-1728-46e0-8a48-feff62da252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with Missing Values:\n",
    "Filling the missing values with right technique can change our results drastically.\n",
    "Also, there is no fixed rule of filling the missing values.\n",
    "No method is perfect for filling the missing values. We need to use our common sense, our logic, or may need to \n",
    "see what works for that particular data set.\n",
    "              \n",
    "Ways of dealing with missing values:\n",
    "Default value: One can fill the missing value by default value on the basis of one's 1) understanding of variable, 2)\n",
    "context / data insight or 3) common sense / logic.\n",
    "\n",
    "Deleting: Suppose in our dataset we have too many missing values in\n",
    "\n",
    "Column, we can drop the column\n",
    "Row, drop the row. Usually we do this for a large enough dataset.\n",
    "                                     \n",
    "Mean/Median/Mode - Imputation: We fill missing values by mean or median or mode(i.e. maximum occuring value). Generally\n",
    "we use mean but if there are some outliers, we fill missing values with median.Mode is used to fill missing values for categorical column.\n",
    "\n",
    "Data Cleaning in Python: the Ultimate Guide\n",
    "\n",
    "Eliminate columns with more than 20% missing values. Again this is very subjective and solely depends on \n",
    "the nature of the dataset and underlying context. We cannot generalize this procedure to all the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30fb4d2c-eb19-4b4e-b31c-770fac5605c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = fraud_data[fraud_data.columns[fraud_data.isnull().mean() < 0.2]]   # We will keep those columns which has missing values less than 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d72969fd-6822-4c4c-8e2b-d1fbf80a561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will fill missing values of numerical variables (or columns) with mean values:\n",
    "num_cols = fraud_data.select_dtypes(include=np.number).columns   # Getting the all numerical columns\n",
    "\n",
    "fraud_data[num_cols] = fraud_data[num_cols].fillna(fraud_data[num_cols].mean())   # Fill the missing values with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae2dc2e3-8337-4b5a-9514-8b71151e3243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling missing values of categorical variables with mode: Mode is maximum occuring element in a variable.\n",
    "cat_cols = fraud_data.select_dtypes(include='object').columns  # Getting all the categorical columns\n",
    "\n",
    "fraud_data[cat_cols] = fraud_data[cat_cols].fillna(fraud_data[cat_cols].mode).iloc[0]   # FIll the missing values with maximum \n",
    "#occuring element in the colunms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82de3538-8d09-4ba3-84f3-6d5abfea27cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransactionID     0.0\n",
       "isFraud           0.0\n",
       "TransactionDT     0.0\n",
       "TransactionAmt    0.0\n",
       "ProductCD         0.0\n",
       "                 ... \n",
       "V317              0.0\n",
       "V318              0.0\n",
       "V319              0.0\n",
       "V320              0.0\n",
       "V321              0.0\n",
       "Length: 182, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look if there still exist any missing values:\n",
    "fraud_data.isnull().sum()/len(fraud_data) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f23b2a4-7600-4dbf-a702-db172bd1498a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now We don't have any missing values in any columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44a176f5-ea7d-4560-9d8b-5d36914838af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding: (Creating Dummies for categorical columns)\n",
    "# In this strategy, each category value is converted into a new column and assigned a 1 or 0 (notation for true/false) value to the column.\n",
    "# In Python there is a class 'OneHotEncoder' in 'sklearn.preprocessing' to do this task,\n",
    "# but here we will use pandas function 'get_dummies()'. This get_dummies() does the same work as done by 'OneHotEncoder' form sklearn.preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b5bbf6c-bf67-40e7-8e6b-b7afa239ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_data = pd.get_dummies(fraud_data, columns=cat_cols)   # earlier we have collected all the categorical columns in cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47afa2d6-db0e-40f6-8b57-ec9e12d67eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>...</th>\n",
       "      <th>V316</th>\n",
       "      <th>V317</th>\n",
       "      <th>V318</th>\n",
       "      <th>V319</th>\n",
       "      <th>V320</th>\n",
       "      <th>V321</th>\n",
       "      <th>ProductCD_H</th>\n",
       "      <th>card4_visa</th>\n",
       "      <th>card6_credit</th>\n",
       "      <th>P_emaildomain_yahoo.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2994681</td>\n",
       "      <td>0</td>\n",
       "      <td>242834</td>\n",
       "      <td>25.000</td>\n",
       "      <td>9803</td>\n",
       "      <td>583.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3557242</td>\n",
       "      <td>0</td>\n",
       "      <td>15123000</td>\n",
       "      <td>117.000</td>\n",
       "      <td>7919</td>\n",
       "      <td>194.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>288.0</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>1707.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3327470</td>\n",
       "      <td>0</td>\n",
       "      <td>8378575</td>\n",
       "      <td>73.773</td>\n",
       "      <td>12778</td>\n",
       "      <td>500.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3118781</td>\n",
       "      <td>0</td>\n",
       "      <td>2607840</td>\n",
       "      <td>400.000</td>\n",
       "      <td>12316</td>\n",
       "      <td>548.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3459772</td>\n",
       "      <td>0</td>\n",
       "      <td>12226544</td>\n",
       "      <td>31.950</td>\n",
       "      <td>9002</td>\n",
       "      <td>453.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 182 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  isFraud  TransactionDT  TransactionAmt  card1  card2  card3  \\\n",
       "0        2994681        0         242834          25.000   9803  583.0  150.0   \n",
       "1        3557242        0       15123000         117.000   7919  194.0  150.0   \n",
       "2        3327470        0        8378575          73.773  12778  500.0  185.0   \n",
       "3        3118781        0        2607840         400.000  12316  548.0  150.0   \n",
       "4        3459772        0       12226544          31.950   9002  453.0  150.0   \n",
       "\n",
       "   card5  addr1  addr2  ...   V316    V317    V318  V319  V320  V321  \\\n",
       "0  226.0  269.0   87.0  ...    0.0     0.0     0.0   0.0   0.0   0.0   \n",
       "1  166.0  181.0   87.0  ...  288.0  1707.0  1707.0   0.0   0.0   0.0   \n",
       "2  224.0  284.0   60.0  ...    0.0     0.0     0.0   0.0   0.0   0.0   \n",
       "3  195.0  441.0   87.0  ...    0.0     0.0     0.0   0.0   0.0   0.0   \n",
       "4  226.0  264.0   87.0  ...    0.0     0.0     0.0   0.0   0.0   0.0   \n",
       "\n",
       "   ProductCD_H  card4_visa  card6_credit  P_emaildomain_yahoo.com  \n",
       "0         True        True          True                     True  \n",
       "1         True        True          True                     True  \n",
       "2         True        True          True                     True  \n",
       "3         True        True          True                     True  \n",
       "4         True        True          True                     True  \n",
       "\n",
       "[5 rows x 182 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb7ddddc-e146-439b-98a7-3cd8f3f9d0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have created a a lot of dummy variables are created like; P_emaildomain_hotmail.com, P_emaildomain_hotmail.de, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4bc111b-8520-4170-834b-ba0b430c5f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Input features and output features\n",
    "X = fraud_data.drop(columns = ['isFraud'])  # Input features\n",
    "y = fraud_data.isFraud   # Output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bae5b544-22e0-4029-b4dd-5e31b2b61a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization/ Normalization:\n",
    "#Performing standardization/normalization would bring all the variables in a dataset to a common scale so that it could\n",
    "#further help in implementing various machine learning models \n",
    "#(where standardization/normalization is a pre-requisite to apply such models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc7365d1-851c-4e8c-8679-30fa838c43a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaled_features = StandardScaler().fit_transform(X)\n",
    "scaled_features = pd.DataFrame(data=scaled_features)\n",
    "scaled_features.columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c72fdd0f-05e4-41e8-a500-8af420969475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TransactionID</th>\n",
       "      <th>TransactionDT</th>\n",
       "      <th>TransactionAmt</th>\n",
       "      <th>card1</th>\n",
       "      <th>card2</th>\n",
       "      <th>card3</th>\n",
       "      <th>card5</th>\n",
       "      <th>addr1</th>\n",
       "      <th>addr2</th>\n",
       "      <th>C1</th>\n",
       "      <th>...</th>\n",
       "      <th>V316</th>\n",
       "      <th>V317</th>\n",
       "      <th>V318</th>\n",
       "      <th>V319</th>\n",
       "      <th>V320</th>\n",
       "      <th>V321</th>\n",
       "      <th>ProductCD_H</th>\n",
       "      <th>card4_visa</th>\n",
       "      <th>card6_credit</th>\n",
       "      <th>P_emaildomain_yahoo.com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.688548</td>\n",
       "      <td>-1.544958</td>\n",
       "      <td>-0.468203</td>\n",
       "      <td>-0.021940</td>\n",
       "      <td>1.412632</td>\n",
       "      <td>-0.286861</td>\n",
       "      <td>0.653753</td>\n",
       "      <td>-0.225982</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>-0.099186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051649</td>\n",
       "      <td>-0.063047</td>\n",
       "      <td>-0.059636</td>\n",
       "      <td>-0.099385</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.615662</td>\n",
       "      <td>1.681426</td>\n",
       "      <td>-0.073540</td>\n",
       "      <td>-0.406928</td>\n",
       "      <td>-1.078794</td>\n",
       "      <td>-0.286861</td>\n",
       "      <td>-0.804662</td>\n",
       "      <td>-1.144356</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>-0.099186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067405</td>\n",
       "      <td>0.347441</td>\n",
       "      <td>0.519006</td>\n",
       "      <td>-0.099385</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266093</td>\n",
       "      <td>0.219070</td>\n",
       "      <td>-0.258976</td>\n",
       "      <td>0.585989</td>\n",
       "      <td>0.881042</td>\n",
       "      <td>2.788641</td>\n",
       "      <td>0.605139</td>\n",
       "      <td>-0.069441</td>\n",
       "      <td>-10.788933</td>\n",
       "      <td>-0.099186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051649</td>\n",
       "      <td>-0.063047</td>\n",
       "      <td>-0.059636</td>\n",
       "      <td>-0.099385</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.959645</td>\n",
       "      <td>-1.032167</td>\n",
       "      <td>1.140478</td>\n",
       "      <td>0.491581</td>\n",
       "      <td>1.188468</td>\n",
       "      <td>-0.286861</td>\n",
       "      <td>-0.099761</td>\n",
       "      <td>1.569022</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>-0.099186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051649</td>\n",
       "      <td>-0.063047</td>\n",
       "      <td>-0.059636</td>\n",
       "      <td>-0.099385</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.043171</td>\n",
       "      <td>1.053404</td>\n",
       "      <td>-0.438389</td>\n",
       "      <td>-0.185621</td>\n",
       "      <td>0.580022</td>\n",
       "      <td>-0.286861</td>\n",
       "      <td>0.653753</td>\n",
       "      <td>-0.278162</td>\n",
       "      <td>0.077832</td>\n",
       "      <td>-0.082944</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051649</td>\n",
       "      <td>-0.063047</td>\n",
       "      <td>-0.059636</td>\n",
       "      <td>-0.099385</td>\n",
       "      <td>-0.10873</td>\n",
       "      <td>-0.108863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 181 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   TransactionID  TransactionDT  TransactionAmt     card1     card2     card3  \\\n",
       "0      -1.688548      -1.544958       -0.468203 -0.021940  1.412632 -0.286861   \n",
       "1       1.615662       1.681426       -0.073540 -0.406928 -1.078794 -0.286861   \n",
       "2       0.266093       0.219070       -0.258976  0.585989  0.881042  2.788641   \n",
       "3      -0.959645      -1.032167        1.140478  0.491581  1.188468 -0.286861   \n",
       "4       1.043171       1.053404       -0.438389 -0.185621  0.580022 -0.286861   \n",
       "\n",
       "      card5     addr1      addr2        C1  ...      V316      V317      V318  \\\n",
       "0  0.653753 -0.225982   0.077832 -0.099186  ... -0.051649 -0.063047 -0.059636   \n",
       "1 -0.804662 -1.144356   0.077832 -0.099186  ...  0.067405  0.347441  0.519006   \n",
       "2  0.605139 -0.069441 -10.788933 -0.099186  ... -0.051649 -0.063047 -0.059636   \n",
       "3 -0.099761  1.569022   0.077832 -0.099186  ... -0.051649 -0.063047 -0.059636   \n",
       "4  0.653753 -0.278162   0.077832 -0.082944  ... -0.051649 -0.063047 -0.059636   \n",
       "\n",
       "       V319     V320      V321  ProductCD_H  card4_visa  card6_credit  \\\n",
       "0 -0.099385 -0.10873 -0.108863          0.0         0.0           0.0   \n",
       "1 -0.099385 -0.10873 -0.108863          0.0         0.0           0.0   \n",
       "2 -0.099385 -0.10873 -0.108863          0.0         0.0           0.0   \n",
       "3 -0.099385 -0.10873 -0.108863          0.0         0.0           0.0   \n",
       "4 -0.099385 -0.10873 -0.108863          0.0         0.0           0.0   \n",
       "\n",
       "   P_emaildomain_yahoo.com  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      0.0  \n",
       "3                      0.0  \n",
       "4                      0.0  \n",
       "\n",
       "[5 rows x 181 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let' see how the data looks like after scaling\n",
    "scaled_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c57b7334-5e55-4703-90f0-5872a9f93eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPlitting the dataset into train and test set:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da50cbd9-9de4-4706-9277-e87da914e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with Imbalanced Data:\n",
    "# Most machine learning algorithms work best when the number of samples in each class are about equal. This is because most algorithms\n",
    "# are designed to maximize accuracy and reduce error. \n",
    "#Again this can't be generalized and we must be very case specific depending on the nature of data and its underlying context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "129b0723-d66c-4a34-b9a6-adeb3fb4081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defferent Techniques:\n",
    "#1) Resampling Techniques - Oversampling Minority Class:\n",
    "#Oversampling can be defined as adding more copies of the minority class. In other words, we are creating artificial/synthetic\n",
    "#data of the minority class (or group).\n",
    "#Oversampling could be a good choice when we don’t have a lot of data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "013e1b23-4764-4c2d-b186-bb8a76a20999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling is located under sklearn.utils\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1eedc300-75f6-4bcc-b042-b69688dba02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate training data back together:\n",
    "train_data= pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb7588d2-93df-4aa9-8526-4ed8e5ced8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate minority and majority class\n",
    "not_fraud = train_data[train_data.isFraud==0]\n",
    "fraud=train_data[train_data.isFraud==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d1bcf38-6ba3-4216-b814-377b6031a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unsample minority; we are oversampling the minority class to match the number of majority class\n",
    "fraud_unsampled = resample(fraud,\n",
    "                           replace=True,  # Sample with replacement\n",
    "                           n_samples = len(not_fraud),  # Match number in majority class\n",
    "                           random_state=27)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "437112a1-d48c-4096-815b-d0a67a7e2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine majority and unsampled minority:\n",
    "unsampled = pd.concat([not_fraud, fraud_unsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ed1c0bc-8c35-4d73-a244-b5b5b98f472b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    39942\n",
       "1    39942\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's check classes count:\n",
    "unsampled.isFraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4c514ae3-3bae-4ed8-b9c1-2fec35645fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can notice here after resampling we have an equal ratio of data points for each class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9d45b7c6-69fb-4f28-8ba4-9e5b825286c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling Techniques - Undersample Majority Class:\n",
    "# Undersampling can be defined as removing some observations of the majority class. Undersampling can be a good choice \n",
    "# when we have a ton of data -think millions of rows. But a drawback is that we are removing information that may be valuable.\n",
    "# This could lead to underfitting and poor generalization to the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86ede0e2-fcb0-4585-ba31-1f6f9ebd810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again we are removing the observations of the majority class to match the number of minority class:\n",
    "# Downsample majority:\n",
    "not_fraud_downsampled = resample(not_fraud,\n",
    "                                replace = False, \n",
    "                                n_samples = len(fraud),   # Match the majority n\n",
    "                                random_state = 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b77b6f54-433a-4757-927a-fb63762666c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COmbine minority and downsampled majority\n",
    "downsampled = pd.concat([not_fraud_downsampled, fraud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84d41d8a-3a0a-433f-b16c-d4a66e446b77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "isFraud\n",
       "0    1395\n",
       "1    1395\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's Check the classes counts:\n",
    "downsampled.isFraud.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a115b412-091a-48d5-b6b0-8e66a2c6c923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we have an equal ratio of fraud to not fraud data points, but in this case a much smaller quantity of data to train the model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b69077f-30c2-46ac-857e-2f6d02b02124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Synthetic Samples: Here we will use imblearn’s SMOTE or Synthetic Minority Oversampling Technique. SMOTE uses a nearest neighbors algorithm \n",
    "#to generate new and synthetic data we can use for training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c9dbb05c-7b18-4042-b01e-02a037e0cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SMOTE:\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(random_state= 25,sampling_strategy=1.0)   # again we are equalizing both the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78b0cf98-1706-433f-8086-8bd4b5c5d393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the sampling :\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "057933e2-9f08-49cb-99fc-4bc754778d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([39942, 39942], dtype=int64))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)   ## Y_train is numpy array, so unique() functions returns the count of all the unique elements in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e2b0a57-4944-4588-b34c-1ad72887c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The count of both classes are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cdb01b2-2b60-4449-b59c-5582d7a121e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion\n",
    "# That's it for this notebook. We learned handling missing values, \n",
    "#one hot encoding, standardization / normalization, what is imbalanced class and three techniques to deal with imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039da93b-b291-4746-b6d5-9a5d5c8d9f82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
